{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w31G0dhZuqbx",
        "outputId": "ba13edd7-c804-4604-a086-82f3e335c84d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   RowID  Body  Sweetness  Smoky  Medicinal  Tobacco  Spicy  Winey  Nutty  \\\n",
            "0    1.0   2.0        2.0    2.0        0.0      0.0    1.0    2.0    2.0   \n",
            "1    2.0   3.0        3.0    1.0        0.0      0.0    3.0    2.0    2.0   \n",
            "2    3.0   1.0        3.0    2.0        0.0      0.0    0.0    0.0    2.0   \n",
            "3    4.0   4.0        1.0    4.0        4.0      0.0    2.0    0.0    1.0   \n",
            "4    5.0   2.0        2.0    2.0        0.0      0.0    1.0    1.0    2.0   \n",
            "\n",
            "   Malty  ...  Distillery_Strathmill  Distillery_Talisker  Distillery_Tamdhu  \\\n",
            "0    2.0  ...                  False                False              False   \n",
            "1    3.0  ...                  False                False              False   \n",
            "2    2.0  ...                  False                False              False   \n",
            "3    2.0  ...                  False                False              False   \n",
            "4    3.0  ...                  False                False              False   \n",
            "\n",
            "   Distillery_Tamnavulin  Distillery_Teaninich  Distillery_Tobermory  \\\n",
            "0                  False                 False                 False   \n",
            "1                  False                 False                 False   \n",
            "2                  False                 False                 False   \n",
            "3                  False                 False                 False   \n",
            "4                  False                 False                 False   \n",
            "\n",
            "   Distillery_Tomatin  Distillery_Tomintoul  Distillery_Tormore  \\\n",
            "0               False                 False               False   \n",
            "1               False                 False               False   \n",
            "2               False                 False               False   \n",
            "3               False                 False               False   \n",
            "4               False                 False               False   \n",
            "\n",
            "   Distillery_Tullibardine  \n",
            "0                    False  \n",
            "1                    False  \n",
            "2                    False  \n",
            "3                    False  \n",
            "4                    False  \n",
            "\n",
            "[5 rows x 97 columns]\n",
            "      RowID  Body  Sweetness  Smoky  Medicinal  Tobacco     Spicy  Winey  \\\n",
            "0  0.000000  0.50   0.333333   0.50        0.0      0.0  0.333333   0.50   \n",
            "1  0.011765  0.75   0.666667   0.25        0.0      0.0  1.000000   0.50   \n",
            "2  0.023529  0.25   0.666667   0.50        0.0      0.0  0.000000   0.00   \n",
            "3  0.035294  1.00   0.000000   1.00        1.0      0.0  0.666667   0.00   \n",
            "4  0.047059  0.50   0.333333   0.50        0.0      0.0  0.333333   0.25   \n",
            "\n",
            "   Nutty     Malty  ...  Distillery_Strathmill  Distillery_Talisker  \\\n",
            "0   0.50  0.666667  ...                    0.0                  0.0   \n",
            "1   0.50  1.000000  ...                    0.0                  0.0   \n",
            "2   0.50  0.666667  ...                    0.0                  0.0   \n",
            "3   0.25  0.666667  ...                    0.0                  0.0   \n",
            "4   0.50  1.000000  ...                    0.0                  0.0   \n",
            "\n",
            "   Distillery_Tamdhu  Distillery_Tamnavulin  Distillery_Teaninich  \\\n",
            "0                0.0                    0.0                   0.0   \n",
            "1                0.0                    0.0                   0.0   \n",
            "2                0.0                    0.0                   0.0   \n",
            "3                0.0                    0.0                   0.0   \n",
            "4                0.0                    0.0                   0.0   \n",
            "\n",
            "   Distillery_Tobermory  Distillery_Tomatin  Distillery_Tomintoul  \\\n",
            "0                   0.0                 0.0                   0.0   \n",
            "1                   0.0                 0.0                   0.0   \n",
            "2                   0.0                 0.0                   0.0   \n",
            "3                   0.0                 0.0                   0.0   \n",
            "4                   0.0                 0.0                   0.0   \n",
            "\n",
            "   Distillery_Tormore  Distillery_Tullibardine  \n",
            "0                 0.0                      0.0  \n",
            "1                 0.0                      0.0  \n",
            "2                 0.0                      0.0  \n",
            "3                 0.0                      0.0  \n",
            "4                 0.0                      0.0  \n",
            "\n",
            "[5 rows x 97 columns]\n",
            "0     2\n",
            "1     4\n",
            "2     2\n",
            "3     0\n",
            "4     1\n",
            "     ..\n",
            "81    1\n",
            "82    2\n",
            "83    2\n",
            "84    1\n",
            "85    0\n",
            "Name: Honey, Length: 86, dtype: int64\n",
            "Epoch 1/2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1250 - loss: 1.6009\n",
            "Epoch 1: val_loss improved from inf to 1.57071, saving model to /content/whisky_modelr.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - accuracy: 0.1102 - loss: 1.5844 - val_accuracy: 0.1333 - val_loss: 1.5707\n",
            "Epoch 2/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2500 - loss: 1.3996\n",
            "Epoch 2: val_loss improved from 1.57071 to 1.47926, saving model to /content/whisky_modelr.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2839 - loss: 1.3851 - val_accuracy: 0.4000 - val_loss: 1.4793\n",
            "Epoch 3/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.5625 - loss: 1.2341\n",
            "Epoch 3: val_loss improved from 1.47926 to 1.40950, saving model to /content/whisky_modelr.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5701 - loss: 1.2364 - val_accuracy: 0.3333 - val_loss: 1.4095\n",
            "Epoch 4/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6875 - loss: 1.0784\n",
            "Epoch 4: val_loss improved from 1.40950 to 1.37259, saving model to /content/whisky_modelr.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6170 - loss: 1.1101 - val_accuracy: 0.3333 - val_loss: 1.3726\n",
            "Epoch 5/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.7500 - loss: 0.9271\n",
            "Epoch 5: val_loss improved from 1.37259 to 1.34780, saving model to /content/whisky_modelr.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5870 - loss: 1.0305 - val_accuracy: 0.2667 - val_loss: 1.3478\n",
            "Epoch 6/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6250 - loss: 1.0320\n",
            "Epoch 6: val_loss improved from 1.34780 to 1.32833, saving model to /content/whisky_modelr.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5635 - loss: 1.0268 - val_accuracy: 0.3333 - val_loss: 1.3283\n",
            "Epoch 7/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.3750 - loss: 1.1078\n",
            "Epoch 7: val_loss improved from 1.32833 to 1.31880, saving model to /content/whisky_modelr.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5344 - loss: 1.0089 - val_accuracy: 0.4000 - val_loss: 1.3188\n",
            "Epoch 8/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5625 - loss: 0.9601\n",
            "Epoch 8: val_loss improved from 1.31880 to 1.31546, saving model to /content/whisky_modelr.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6569 - loss: 0.9337 - val_accuracy: 0.3333 - val_loss: 1.3155\n",
            "Epoch 9/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.6250 - loss: 1.0652\n",
            "Epoch 9: val_loss did not improve from 1.31546\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6837 - loss: 0.9535 - val_accuracy: 0.3333 - val_loss: 1.3223\n",
            "Epoch 10/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.8295\n",
            "Epoch 10: val_loss did not improve from 1.31546\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7339 - loss: 0.8649 - val_accuracy: 0.3333 - val_loss: 1.3389\n",
            "Epoch 11/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.7901\n",
            "Epoch 11: val_loss did not improve from 1.31546\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7339 - loss: 0.8134 - val_accuracy: 0.3333 - val_loss: 1.3433\n",
            "Epoch 12/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8125 - loss: 0.6820\n",
            "Epoch 12: val_loss did not improve from 1.31546\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7951 - loss: 0.7354 - val_accuracy: 0.3333 - val_loss: 1.3288\n",
            "Epoch 13/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.5627\n",
            "Epoch 13: val_loss did not improve from 1.31546\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8498 - loss: 0.6761 - val_accuracy: 0.3333 - val_loss: 1.3385\n",
            "Epoch 14/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8750 - loss: 0.5923\n",
            "Epoch 14: val_loss did not improve from 1.31546\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8330 - loss: 0.6466 - val_accuracy: 0.3333 - val_loss: 1.3243\n",
            "Epoch 15/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.5391\n",
            "Epoch 15: val_loss improved from 1.31546 to 1.31277, saving model to /content/whisky_modelr.keras\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9021 - loss: 0.5964 - val_accuracy: 0.3333 - val_loss: 1.3128\n",
            "Epoch 16/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8750 - loss: 0.6503\n",
            "Epoch 16: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9198 - loss: 0.5813 - val_accuracy: 0.3333 - val_loss: 1.3365\n",
            "Epoch 17/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8750 - loss: 0.5247\n",
            "Epoch 17: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9120 - loss: 0.5172 - val_accuracy: 0.3333 - val_loss: 1.3485\n",
            "Epoch 18/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9375 - loss: 0.5500\n",
            "Epoch 18: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9465 - loss: 0.4732 - val_accuracy: 0.3333 - val_loss: 1.3677\n",
            "Epoch 19/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.3470\n",
            "Epoch 19: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9778 - loss: 0.3578 - val_accuracy: 0.3333 - val_loss: 1.3960\n",
            "Epoch 20/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.2695\n",
            "Epoch 20: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9700 - loss: 0.3045 - val_accuracy: 0.3333 - val_loss: 1.4354\n",
            "Epoch 21/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.2802\n",
            "Epoch 21: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9622 - loss: 0.2817 - val_accuracy: 0.3333 - val_loss: 1.4145\n",
            "Epoch 22/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.2467\n",
            "Epoch 22: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9889 - loss: 0.2292 - val_accuracy: 0.3333 - val_loss: 1.4523\n",
            "Epoch 23/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1612\n",
            "Epoch 23: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9811 - loss: 0.1803 - val_accuracy: 0.3333 - val_loss: 1.4710\n",
            "Epoch 24/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1441\n",
            "Epoch 24: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1558 - val_accuracy: 0.3333 - val_loss: 1.5019\n",
            "Epoch 25/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1657\n",
            "Epoch 25: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.1436 - val_accuracy: 0.3333 - val_loss: 1.5684\n",
            "Epoch 26/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0812\n",
            "Epoch 26: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1044 - val_accuracy: 0.3333 - val_loss: 1.6289\n",
            "Epoch 27/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0892\n",
            "Epoch 27: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0900 - val_accuracy: 0.3333 - val_loss: 1.6792\n",
            "Epoch 28/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0756\n",
            "Epoch 28: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0808 - val_accuracy: 0.3333 - val_loss: 1.6993\n",
            "Epoch 29/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0982\n",
            "Epoch 29: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0785 - val_accuracy: 0.3333 - val_loss: 1.7222\n",
            "Epoch 30/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0835\n",
            "Epoch 30: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0671 - val_accuracy: 0.3333 - val_loss: 1.7456\n",
            "Epoch 31/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0471\n",
            "Epoch 31: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0533 - val_accuracy: 0.3333 - val_loss: 1.7630\n",
            "Epoch 32/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0424\n",
            "Epoch 32: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0477 - val_accuracy: 0.3333 - val_loss: 1.7945\n",
            "Epoch 33/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0390\n",
            "Epoch 33: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0405 - val_accuracy: 0.3333 - val_loss: 1.8359\n",
            "Epoch 34/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0338\n",
            "Epoch 34: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0390 - val_accuracy: 0.3333 - val_loss: 1.8760\n",
            "Epoch 35/2000\n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0318\n",
            "Epoch 35: val_loss did not improve from 1.31277\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0332 - val_accuracy: 0.3333 - val_loss: 1.9116\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3462 - loss: 1.8071\n",
            "Test accuracy: 0.3461538553237915\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 데이터 세트를 읽어들인다.\n",
        "df = pd.read_csv(\"/content/whisky.csv\", sep=',')\n",
        "\n",
        "# 결측치 제거\n",
        "df = df.dropna(subset=['Honey'])\n",
        "\n",
        "# 정수형 변환\n",
        "df['Honey'] = df['Honey'].astype(int)\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns=['Distillery'], drop_first=True)\n",
        "\n",
        "# 입력 데이터 X : 'Honey' 컬럼 제외한 모든 컬럼 사용\n",
        "X = df_encoded.drop(columns=['Honey'])\n",
        "\n",
        "y = df_encoded['Honey']\n",
        "\n",
        "y=keras.utils.to_categorical(y)\n",
        "\n",
        "print()\n",
        "\n",
        "mms=MinMaxScaler()\n",
        "mms.fit(X)\n",
        "print(X.head())\n",
        "X_mms=mms.transform(X)\n",
        "X = pd.DataFrame(X_mms, columns=X.columns, index=list(X.index.values))\n",
        "\n",
        "\n",
        "print(X.head())\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,shuffle=True)\n",
        "print(df.Honey)\n",
        "\n",
        "\n",
        "# 케라스 모델을 생성한다.\n",
        "input_dim = X.shape[1]\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(64, activation='tanh', input_shape=(input_dim,)))\n",
        "model.add(keras.layers.Dense(64, activation='tanh'))\n",
        "model.add(keras.layers.Dense(64, activation='tanh'))\n",
        "model.add(keras.layers.Dense(32, activation='tanh'))\n",
        "model.add(keras.layers.Dense(5,activation='softmax'))\n",
        "\n",
        "# 케라스 모델을 컴파일한다.\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# 20회 이상 결과가 향상되지 않으면 자동으로 중단되게끔 합니다.\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "# 모델의 이름을 정합니다.\n",
        "modelpath='/content/whisky_modelr.keras'\n",
        "\n",
        "# 최적화 모델을 업데이트하고 저장합니다.\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "# 실행 관련 설정을 하는 부분입니다. 전체의 20%를 검증셋으로 설정합니다.\n",
        "history = model.fit(X_train, y_train, validation_split=0.25, epochs=2000, batch_size=16, callbacks=[early_stopping_callback, checkpointer])\n",
        "\n",
        "# 테스트 결과를 출력합니다.\n",
        "score=model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', score[1])\n"
      ]
    }
  ]
}